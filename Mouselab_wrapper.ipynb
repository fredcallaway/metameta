{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mouselab import MouselabEnv\n",
    "from distributions import Categorical\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "class MouseLabWrapperEnv(gym.Env):\n",
    "    def __init__(self,N,cost_range):\n",
    "        super(MouseLabWrapperEnv, self).__init__()\n",
    "\n",
    "        self.N = N\n",
    "        self.cost_range = cost_range\n",
    "        self.num_node_values = 2 #we're hardcoding the number of possible node values, but not the values themselves\n",
    "        self.action_space = spaces.Discrete(N) #one action for each non-root node plus a terminal action makes N-1 + 1 = N actions\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.N+self.num_node_values + 1,self.N), dtype=np.float32) #this is \n",
    "        self._terminal_action = 0 #Note that this differs from the convention in MouseLabEnv\n",
    "        self.reset()\n",
    "        \n",
    "    def encode_state_as_obs(self,state):\n",
    "        vals = np.array(env.reward_distribution.vals)\n",
    "        belief_state = np.vstack([[0,0]] + [o.probs if isinstance(o,Categorical) \n",
    "                        else np.arange(len(vals))==np.argmin(np.abs(vals-o))\n",
    "                        for o in state[1:]])\n",
    "        #Belief states are encoded as a N x num_node_values matrix, \n",
    "        #in which the i,j-th entry is the probability that node i has value reward_distribution.vals[j]\n",
    "        #for revealed nodes, this probability is 0 or 1\n",
    "        #for unrevealed nodes, the probability is copied from reward_distribution.probs\n",
    "        #note that this encoding does not inform the agent of the actual values in reward_distribution.vals\n",
    "        return np.hstack([self.adjacency_matrix,belief_state,np.full(shape=[self.N,1],fill_value=self.cost)])\n",
    "\n",
    "    def step(self,action):\n",
    "        #an action is an integer: 0 means terminating, any non-zero action means revealing the value of that node\n",
    "        assert self.action_space.contains(action)\n",
    "        if action==self._terminal_action:\n",
    "            _ , reward, done, _ = self.env.step(self.env.term_action)\n",
    "            #This is necessary to get around the convention\n",
    "        else:\n",
    "            _ , reward, done, _ = self.env.step(action)\n",
    "        return self.encode_state_as_obs(self.env._state), reward, done, {}    \n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        self.cost = np.random.uniform(*self.cost_range)\n",
    "    \n",
    "        p = np.random.uniform(.1, .9)\n",
    "        x = (1-p) / p\n",
    "        self.reward_distribution = Categorical([-1, x], [(1-p), p])\n",
    "        #We can make the set of possible reward distributions larger, this is a first attempt\n",
    "\n",
    "        self.env = MouselabEnv.new_erdos_renyi(self.N, reward=self.reward_distribution, cost=self.cost, simple_features = True)\n",
    "        self.adjacency_matrix = np.zeros([len(self.env.tree),len(self.env.tree)])\n",
    "        for vertex,edges in enumerate(self.env.tree):\n",
    "            for neighbor in edges:\n",
    "                self.adjacency_matrix[vertex,neighbor] = 1\n",
    "                \n",
    "    def render():\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MouseLabWrapperEnv(20,[0,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs,reward,done,_ = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 23)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
